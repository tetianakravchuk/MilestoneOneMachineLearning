{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Milestone One: Gathering your Team, Understanding the Problem,  Exploring the Data\n",
    "\n",
    "#### Due: Midnight on July 20th (with 2-hour grace period)\n",
    "\n",
    "#### There will be no late period on this homework, as we need to start manual grading immediately! \n",
    "\n",
    "\n",
    "\n",
    "### What We Will Do in This Milestone Assignment\n",
    "\n",
    "1. You will convene your team and fill out the Team Contract (in the Homework Repo), to be submitted to Gradescope.\n",
    "2. You must select a team leader for the purpose of submitting this notebook, after the team collaborates to complete the assignment. This <a href=https://guides.gradescope.com/hc/en-us/articles/21863861823373-Adding-Group-Members-to-a-Submission>link</a> describes how to add group members to your leader's submission. \n",
    "3. At the conclusion of your work on this Milestone, you will complete an Individual Evaluation of your team's work (in the Homework Repo) and upload it *individually* to Gradescope.\n",
    "4. We will follow a simplified version of the **Machine Learning Project Checklist** in Appendix A in our textbook *Hands-On Machine Learning* (pp.779):  \n",
    "\n",
    ">Part 1:\tFrame the problem and look at the big picture  \n",
    "Part 2: Download and perform preliminary exploration of the data  \n",
    "Part 3: Clean the Data: Drop, Impute, and Encode   \n",
    "Part 4: Explore Feature Relationships  \n",
    "Part 5: Investigate Feature Engineering options to better expose the underlying data patterns  \n",
    "\n",
    "### The Dataset\n",
    "\n",
    "All teams will use the same dataset. It is a smaller version of the Zillow housing dataset that was used in the\n",
    "Zillow Million Dollar Prize which ran on Kaggle in 2017 (sorry, the contest is closed, so you can't win any money\n",
    "with this project!).  We will try to predict the assessed tax value (`'taxvaluedollarcnt'`) of the property from a large collection\n",
    "of descriptors. Some features are closely related and some are obviously useless.  There are potential outliers and also quite a few missing values. \n",
    "\n",
    "This is a good example of a dataset which has not been predigested for you on Kaggle, and should give you a good chance to\n",
    "try all the various tools in your toolbox!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Useful Imports\n",
    "# =============================\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
    "\n",
    "# Scikit-learn (Machine Learning)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    cross_val_score, \n",
    "    GridSearchCV, \n",
    "    RandomizedSearchCV, \n",
    "    RepeatedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, f_regression, SelectKBest\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Kaggle and Progress Tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================\n",
    "# Global Variables\n",
    "# =============================\n",
    "random_state = 42\n",
    "\n",
    "# =============================\n",
    "# Utility Functions\n",
    "# =============================\n",
    "\n",
    "# Format y-axis labels as dollars with commas (optional)\n",
    "def dollar_format(x, pos):\n",
    "    return f'${x:,.0f}'\n",
    "\n",
    "# Convert seconds to HH:MM:SS format\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelude: Download the Zillow Housing Dataset \n",
    "\n",
    "The code cell below will load the dataset for you.    \n",
    "\n",
    "> **Notice that before downloading, this cell first checks whether the files already exist.** \n",
    "\n",
    "For a detailed description of the dataset features, please refer to  **Appendix 1** below. \n",
    "\n",
    "**Note:** Do **not** perform a train/test split for this milestone (unlike HOML suggests), since you need to do the split **after** any data preparation and feature engineering. You can wait until Milestone 2 to do the split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://www.cs.bu.edu/fac/snyder/cs505/Data/zillow_dataset.csv\"\n",
    "\n",
    "filename = os.path.basename(urlparse(url).path)\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    try:\n",
    "        print(\"Downloading the file...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"File downloaded successfully.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading the file: {e}\")\n",
    "else:\n",
    "    print(\"File already exists. Skipping download.\")\n",
    "\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Frame the problem and look at the big picture [3 pts]\n",
    "\n",
    "This part is a bit vague, since this project is not taking place in an actual business, but for the sake of exercizing all the steps, **pretend** that you are working at Zillow as a data analyst and are given this dataset and asked to\n",
    "- Analyze and understand the data; \n",
    "- Create a regression model;\n",
    "- Give a presentation to the marketing team about your results.  \n",
    "\n",
    "#### **1 Discussion:** \n",
    "\n",
    "AFTER doing your EDA, come back and answer each of the following 3 questions in a *concise and informative paragraph between the lines;* you may wish to use your own business or home-buying experience, or to do some online research about the issues before you propose your ideas. (Don't stress about this, but *humor your professor and give it your best shot!*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1:**  What is the objective of this project in business terms?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2:**  How will your solution be used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3:**  How should success (or failure) be measured?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Part 1: Frame the Problem \n",
    "### **1.1: What is the objective of this project in business terms?**\n",
    "\n",
    "We want to help Zillow figure out how much a house is worth based on features like square footage, number of bedrooms, bathrooms, and lot size. The goal is to build a machine learning model that can predict a home's tax-assessed value. This helps Zillow give more accurate price estimates to buyers, sellers, and real estate investors.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.2: How will our project be used?**\n",
    "\n",
    "Our model will be used by Zillow's tools to estimate home values, especially when some information is missing or outdated. These predictions can show up on Zillow’s website (like in Zestimate), or be used internally by their marketing team to make smarter decisions about pricing, ads, and targeting.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.3: How should success be measured?**\n",
    "\n",
    "We’ll check if our model is good by measuring how close its predictions are to the real values. We’ll use metrics like **MAE (Mean Absolute Error)** or **RMSE (Root Mean Squared Error)**. A low error means our model is doing well. It’s also important that the model works for all types of homes — not just the expensive ones or those in certain neighborhoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Download and perform preliminary exploration of the data [4 pts]\n",
    "\n",
    "### Part 2.A: Load the data into a dataframe and study each feature/column and its characteristics:\n",
    "- Name\n",
    "- Type (categorical, int/float, text, etc.)\n",
    "- Apparent usefulness for the task\n",
    "- Approximate % of missing values\n",
    "- How many unique values\n",
    "\n",
    "**Note:** The **target** is the last column `'taxvaluedollarcnt'` -- pay particular attention to this during the EDA process. \n",
    "  \n",
    "Hint: Just use `.head()`, `.info()`, and `.nunique()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Part 2.A: Preliminary Exploration of the Dataset\n",
    "\n",
    "We loaded the Zillow dataset and examined each feature based on:\n",
    "\n",
    "- Data type\n",
    "- % of missing values\n",
    "- Number of unique values\n",
    "- Rough guess of usefulness for predicting tax value\n",
    "\n",
    "Here are some key takeaways:\n",
    "\n",
    "- `parcelid`: A unique ID per property (not useful for modeling).\n",
    "- `airconditioningtypeid`: ~68% missing — may be useful but risky.\n",
    "- `architecturalstyletypeid`, `basementsqft`: Over 99% missing — we’ll likely drop these.\n",
    "- `bathroomcnt` and `bedroomcnt`: No missing values and important for home value — we will keep these.\n",
    "- `taxvaluedollarcnt` (our **target variable**): The tax-assessed value we aim to predict.\n",
    "\n",
    "Overall, many features have missing values. We’ll need to drop or impute them wisely in Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All packages imported successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Column Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Data Type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Missing (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unique Values",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Usefulness (Rough Guess)",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6ec8264a-c3f1-4d0a-a777-e9cc8de19340",
       "rows": [
        [
         "0",
         "parcelid",
         "int64",
         "0.0",
         "77414",
         "Likely Not Useful"
        ],
        [
         "1",
         "airconditioningtypeid",
         "float64",
         "67.77988223622332",
         "5",
         "Likely Not Useful"
        ],
        [
         "2",
         "architecturalstyletypeid",
         "float64",
         "99.73329210312706",
         "5",
         "Likely Not Useful"
        ],
        [
         "3",
         "basementsqft",
         "float64",
         "99.93557780268769",
         "43",
         "Too Much Missing Data"
        ],
        [
         "4",
         "bathroomcnt",
         "float64",
         "0.04380709417236803",
         "22",
         "Likely Useful"
        ],
        [
         "5",
         "bedroomcnt",
         "float64",
         "0.04380709417236803",
         "16",
         "Likely Useful"
        ],
        [
         "6",
         "buildingclasstypeid",
         "float64",
         "99.9806733408063",
         "2",
         "Likely Not Useful"
        ],
        [
         "7",
         "buildingqualitytypeid",
         "float64",
         "35.82389548142708",
         "12",
         "Likely Not Useful"
        ],
        [
         "8",
         "calculatedbathnbr",
         "float64",
         "0.837488565059977",
         "21",
         "Maybe Useful"
        ],
        [
         "9",
         "decktypeid",
         "float64",
         "99.20889541700488",
         "1",
         "Likely Not Useful"
        ],
        [
         "10",
         "finishedfloor1squarefeet",
         "float64",
         "92.22166389651218",
         "1787",
         "Likely Useful"
        ],
        [
         "11",
         "calculatedfinishedsquarefeet",
         "float64",
         "0.3027843273678379",
         "4972",
         "Likely Useful"
        ],
        [
         "12",
         "finishedsquarefeet12",
         "float64",
         "4.754358161648177",
         "4868",
         "Likely Useful"
        ],
        [
         "13",
         "finishedsquarefeet13",
         "float64",
         "99.94588535425765",
         "13",
         "Likely Useful"
        ],
        [
         "14",
         "finishedsquarefeet15",
         "float64",
         "96.09988017471301",
         "1724",
         "Likely Useful"
        ],
        [
         "15",
         "finishedsquarefeet50",
         "float64",
         "92.22166389651218",
         "1807",
         "Likely Useful"
        ],
        [
         "16",
         "finishedsquarefeet6",
         "float64",
         "99.502660636749",
         "350",
         "Likely Useful"
        ],
        [
         "17",
         "fips",
         "float64",
         "0.04380709417236803",
         "3",
         "Maybe Useful"
        ],
        [
         "18",
         "fireplacecnt",
         "float64",
         "89.32008812956592",
         "5",
         "Likely Useful"
        ],
        [
         "19",
         "fullbathcnt",
         "float64",
         "0.837488565059977",
         "13",
         "Likely Useful"
        ],
        [
         "20",
         "garagecarcnt",
         "float64",
         "67.11891049179906",
         "14",
         "Likely Useful"
        ],
        [
         "21",
         "garagetotalsqft",
         "float64",
         "67.11891049179906",
         "839",
         "Maybe Useful"
        ],
        [
         "22",
         "hashottuborspa",
         "object",
         "98.01708476672722",
         "1",
         "Too Much Missing Data"
        ],
        [
         "23",
         "heatingorsystemtypeid",
         "float64",
         "36.13054514063366",
         "10",
         "Likely Not Useful"
        ],
        [
         "24",
         "latitude",
         "float64",
         "0.04380709417236803",
         "64038",
         "Maybe Useful"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 25
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing (%)</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Usefulness (Rough Guess)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parcelid</td>\n",
       "      <td>int64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77414</td>\n",
       "      <td>Likely Not Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airconditioningtypeid</td>\n",
       "      <td>float64</td>\n",
       "      <td>67.779882</td>\n",
       "      <td>5</td>\n",
       "      <td>Likely Not Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>architecturalstyletypeid</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.733292</td>\n",
       "      <td>5</td>\n",
       "      <td>Likely Not Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basementsqft</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.935578</td>\n",
       "      <td>43</td>\n",
       "      <td>Too Much Missing Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bathroomcnt</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.043807</td>\n",
       "      <td>22</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bedroomcnt</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.043807</td>\n",
       "      <td>16</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>buildingclasstypeid</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.980673</td>\n",
       "      <td>2</td>\n",
       "      <td>Likely Not Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>buildingqualitytypeid</td>\n",
       "      <td>float64</td>\n",
       "      <td>35.823895</td>\n",
       "      <td>12</td>\n",
       "      <td>Likely Not Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>calculatedbathnbr</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.837489</td>\n",
       "      <td>21</td>\n",
       "      <td>Maybe Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>decktypeid</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.208895</td>\n",
       "      <td>1</td>\n",
       "      <td>Likely Not Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>finishedfloor1squarefeet</td>\n",
       "      <td>float64</td>\n",
       "      <td>92.221664</td>\n",
       "      <td>1787</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>calculatedfinishedsquarefeet</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.302784</td>\n",
       "      <td>4972</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>finishedsquarefeet12</td>\n",
       "      <td>float64</td>\n",
       "      <td>4.754358</td>\n",
       "      <td>4868</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>finishedsquarefeet13</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.945885</td>\n",
       "      <td>13</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>finishedsquarefeet15</td>\n",
       "      <td>float64</td>\n",
       "      <td>96.099880</td>\n",
       "      <td>1724</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>finishedsquarefeet50</td>\n",
       "      <td>float64</td>\n",
       "      <td>92.221664</td>\n",
       "      <td>1807</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>finishedsquarefeet6</td>\n",
       "      <td>float64</td>\n",
       "      <td>99.502661</td>\n",
       "      <td>350</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fips</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.043807</td>\n",
       "      <td>3</td>\n",
       "      <td>Maybe Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fireplacecnt</td>\n",
       "      <td>float64</td>\n",
       "      <td>89.320088</td>\n",
       "      <td>5</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fullbathcnt</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.837489</td>\n",
       "      <td>13</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>garagecarcnt</td>\n",
       "      <td>float64</td>\n",
       "      <td>67.118910</td>\n",
       "      <td>14</td>\n",
       "      <td>Likely Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>garagetotalsqft</td>\n",
       "      <td>float64</td>\n",
       "      <td>67.118910</td>\n",
       "      <td>839</td>\n",
       "      <td>Maybe Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hashottuborspa</td>\n",
       "      <td>object</td>\n",
       "      <td>98.017085</td>\n",
       "      <td>1</td>\n",
       "      <td>Too Much Missing Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>heatingorsystemtypeid</td>\n",
       "      <td>float64</td>\n",
       "      <td>36.130545</td>\n",
       "      <td>10</td>\n",
       "      <td>Likely Not Useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>latitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.043807</td>\n",
       "      <td>64038</td>\n",
       "      <td>Maybe Useful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Column Name Data Type  Missing (%)  Unique Values  \\\n",
       "0                       parcelid     int64     0.000000          77414   \n",
       "1          airconditioningtypeid   float64    67.779882              5   \n",
       "2       architecturalstyletypeid   float64    99.733292              5   \n",
       "3                   basementsqft   float64    99.935578             43   \n",
       "4                    bathroomcnt   float64     0.043807             22   \n",
       "5                     bedroomcnt   float64     0.043807             16   \n",
       "6            buildingclasstypeid   float64    99.980673              2   \n",
       "7          buildingqualitytypeid   float64    35.823895             12   \n",
       "8              calculatedbathnbr   float64     0.837489             21   \n",
       "9                     decktypeid   float64    99.208895              1   \n",
       "10      finishedfloor1squarefeet   float64    92.221664           1787   \n",
       "11  calculatedfinishedsquarefeet   float64     0.302784           4972   \n",
       "12          finishedsquarefeet12   float64     4.754358           4868   \n",
       "13          finishedsquarefeet13   float64    99.945885             13   \n",
       "14          finishedsquarefeet15   float64    96.099880           1724   \n",
       "15          finishedsquarefeet50   float64    92.221664           1807   \n",
       "16           finishedsquarefeet6   float64    99.502661            350   \n",
       "17                          fips   float64     0.043807              3   \n",
       "18                  fireplacecnt   float64    89.320088              5   \n",
       "19                   fullbathcnt   float64     0.837489             13   \n",
       "20                  garagecarcnt   float64    67.118910             14   \n",
       "21               garagetotalsqft   float64    67.118910            839   \n",
       "22                hashottuborspa    object    98.017085              1   \n",
       "23         heatingorsystemtypeid   float64    36.130545             10   \n",
       "24                      latitude   float64     0.043807          64038   \n",
       "\n",
       "   Usefulness (Rough Guess)  \n",
       "0         Likely Not Useful  \n",
       "1         Likely Not Useful  \n",
       "2         Likely Not Useful  \n",
       "3     Too Much Missing Data  \n",
       "4             Likely Useful  \n",
       "5             Likely Useful  \n",
       "6         Likely Not Useful  \n",
       "7         Likely Not Useful  \n",
       "8              Maybe Useful  \n",
       "9         Likely Not Useful  \n",
       "10            Likely Useful  \n",
       "11            Likely Useful  \n",
       "12            Likely Useful  \n",
       "13            Likely Useful  \n",
       "14            Likely Useful  \n",
       "15            Likely Useful  \n",
       "16            Likely Useful  \n",
       "17             Maybe Useful  \n",
       "18            Likely Useful  \n",
       "19            Likely Useful  \n",
       "20            Likely Useful  \n",
       "21             Maybe Useful  \n",
       "22    Too Much Missing Data  \n",
       "23        Likely Not Useful  \n",
       "24             Maybe Useful  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-import necessary libraries and reload the dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"✅ All packages imported successfully!\")\n",
    "\n",
    "zillow_path = \"zillow_dataset.csv\"\n",
    "df = pd.read_csv(zillow_path)\n",
    "\n",
    "# Create a summary DataFrame to analyze each column\n",
    "data_summary = pd.DataFrame({\n",
    "    'Data Type': df.dtypes,\n",
    "    'Missing (%)': df.isnull().mean() * 100,\n",
    "    'Unique Values': df.nunique()\n",
    "})\n",
    "\n",
    "# Add a rough guess for usefulness based on column name and type\n",
    "def guess_usefulness(col):\n",
    "    name = col.lower()\n",
    "    if 'id' in name or 'flag' in name:\n",
    "        return 'Likely Not Useful'\n",
    "    if 'taxvaluedollarcnt' in name or 'squarefeet' in name or 'cnt' in name or 'yearbuilt' in name:\n",
    "        return 'Likely Useful'\n",
    "    if df[col].isnull().mean() > 0.9:\n",
    "        return 'Too Much Missing Data'\n",
    "    return 'Maybe Useful'\n",
    "\n",
    "data_summary['Usefulness (Rough Guess)'] = data_summary.index.to_series().map(guess_usefulness)\n",
    "\n",
    "# Reset index for display\n",
    "data_summary.reset_index(inplace=True)\n",
    "data_summary.rename(columns={'index': 'Column Name'}, inplace=True)\n",
    "\n",
    "# Show the summary table\n",
    "data_summary.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.A Discussion:** Answer the following questions.\n",
    "\n",
    "**2.A.1:**  Which features are categorical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**2.A.2:**  Are there any features which appear at first glance to be **useless** for the business purpose of this project and should be deleted?  Give examples and describe your reasoning briefly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**2.A.3:**  Are there any features which appear to be **useless** because of the percentage of missing values?  If so, give an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**2.A.4:**  Are there any features which appear to be **useless** because of the number of unique values?  If so, give an example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ 2.A Discussion: Understanding the Features\n",
    "\n",
    "### **2.A.1: Which features are categorical?**\n",
    "\n",
    "Some features are clearly categorical because they represent **types, flags, or encoded categories**. Examples include:\n",
    "\n",
    "- `airconditioningtypeid` – different types of A/C systems\n",
    "- `propertylandusetypeid` – what kind of land use the property has\n",
    "- `regionidcity`, `regionidcounty`, `regionidzip` – geographic categorical IDs\n",
    "- `buildingqualitytypeid` – rating of the building's quality\n",
    "- `heatingorsystemtypeid` – type of heating system\n",
    "- `fireplaceflag` – yes/no (1/0) indicator for fireplace presence\n",
    "\n",
    "---\n",
    "\n",
    "### **2.A.2: Are there features that are useless for the business purpose of this project?**\n",
    "\n",
    "Yes — some columns don’t help with predicting home value and should be dropped. For example:\n",
    "\n",
    "- `parcelid`, `id`, and other ID-like columns — these are just unique identifiers with no predictive power.\n",
    "- `assessmentyear` — the year is the same for nearly all rows (2016), so it doesn’t help differentiate properties.\n",
    "- `propertyzoningdesc` — too many unique values and inconsistent formats.\n",
    "- `censustractandblock` — a long numeric code that’s hard to interpret directly.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.A.3: Are there features that are useless because of missing values?**\n",
    "\n",
    "Yes — some features have **over 90% missing data**, so they’re not reliable for modeling. Examples:\n",
    "\n",
    "- `basementsqft` – 99.9% missing\n",
    "- `architecturalstyletypeid` – 99.7% missing\n",
    "- `yardbuildingsqft17`, `fireplaceflag`, etc. – also mostly empty\n",
    "\n",
    "We would likely drop these to avoid skewing or complicating imputation.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.A.4: Are there features that are useless due to the number of unique values?**\n",
    "\n",
    "Yes — features with either **only one value** or **a unique value for nearly every row** don’t help. For example:\n",
    "\n",
    "- `parcelid` — almost every row has a unique parcel ID.\n",
    "- `censustractandblock` — also nearly unique per row.\n",
    "- Columns like `rawcensustractandblock`, `regionidtract` — similar issue.\n",
    "\n",
    "These won’t help the model learn general patterns and are better off removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.B: Exploratory Data Analysis (EDA) -- Feature-Level Visualization  \n",
    "\n",
    "- To get an overview, generate histograms for all features using `df.hist()`  (Hint: increase the figsize and set the layout to `(-1,m)` to get  `m` columns and as many rows as necessary.)\n",
    "- Generate individual visualizations for the **target and three (3)** other interesting-looking features in the dataset (i.e., a total of 4):  \n",
    "    - Use appropriate plot types (e.g., histograms and boxplots for numerical features, bar plots for categorical features) to understand distributions and identify potential outliers for these three.\n",
    "    - Use as many code cells as you need, and give comments describing what each cell does.\n",
    "    - Answer the discussion question posed (you should choose 3 features for which you can say something interesting in the discussion).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.B Discussion:** Describe in a paragraph what you learned in your detailed examination of the features you explored:\n",
    "- What is the distribution (normal, exponential, etc.) if any?\n",
    "- Any problems (e.g., outliers, any odd characteristics)?\n",
    "- Anything else interesting? Why did you choose it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/zillow_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m zillow_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/data/zillow_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(zillow_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a summary DataFrame to analyze each column\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data_summary \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData Type\u001b[39m\u001b[38;5;124m'\u001b[39m: df\u001b[38;5;241m.\u001b[39mdtypes,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m: df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnique Values\u001b[39m\u001b[38;5;124m'\u001b[39m: df\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[1;32m     12\u001b[0m })\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/zillow_dataset.csv'"
     ]
    }
   ],
   "source": [
    "# Re-import necessary libraries and reload the dataset after reset\n",
    "import pandas as pd\n",
    "\n",
    "zillow_path = \"/mnt/data/zillow_dataset.csv\"\n",
    "df = pd.read_csv(zillow_path)\n",
    "\n",
    "# Create a summary DataFrame to analyze each column\n",
    "data_summary = pd.DataFrame({\n",
    "    'Data Type': df.dtypes,\n",
    "    'Missing (%)': df.isnull().mean() * 100,\n",
    "    'Unique Values': df.nunique()\n",
    "})\n",
    "\n",
    "# Add a rough guess for usefulness based on column name and type\n",
    "def guess_usefulness(col):\n",
    "    name = col.lower()\n",
    "    if 'id' in name or 'flag' in name:\n",
    "        return 'Likely Not Useful'\n",
    "    if 'taxvaluedollarcnt' in name or 'squarefeet' in name or 'cnt' in name or 'yearbuilt' in name:\n",
    "        return 'Likely Useful'\n",
    "    if df[col].isnull().mean() > 0.9:\n",
    "        return 'Too Much Missing Data'\n",
    "    return 'Maybe Useful'\n",
    "\n",
    "data_summary['Usefulness (Rough Guess)'] = data_summary.index.to_series().map(guess_usefulness)\n",
    "\n",
    "# Reset index for display\n",
    "data_summary.reset_index(inplace=True)\n",
    "data_summary.rename(columns={'index': 'Column Name'}, inplace=True)\n",
    "\n",
    "# Display top 25 rows for review\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Feature Summary\", dataframe=data_summary.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3:  Clean the Data: Drop, Impute, and Encode [6 pts]\n",
    "\n",
    "\n",
    "\n",
    "**Important Notes:**\n",
    "- You should review your Homework 4 before doing this section!\n",
    "- Create new names for modified data at each stage to avoid problems with global variables.\n",
    "- Whenever possible, write functions for all data transformations you apply, for these reasons:\n",
    "    - So you can easily prepare the data the next time you get a fresh dataset\n",
    "    - So you can apply these transformations in future projects\n",
    "    - To clean and prepare new data instances once your solution is live\n",
    "    - To make it easy to treat your preparation choices as hyperparameters\n",
    "    - [To apply the same transformations to your test set if train/test split already done -- not applicable here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.A: Drop features you judge to be unsuitable for the regression task\n",
    "\n",
    "Your call, based on any research you can do to understand the feature (hopefully IRL you would have a domain expert to help with this, but do your best).   \n",
    "\n",
    "Note: Do not drop features because of too many missing values, that's the next task! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.A Discussion:** Justify in a paragraph your decisions about which features to drop. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.B: Drop **features** with \"too many\" null values\n",
    "\n",
    "Your code in the next cell(s). Make a judgement call about what \"too many\" means and briefly describe your reasoning in the discussion.   \n",
    "\n",
    "Note: \"Too many\" may depend on what the non-null values look like, be sure to investigate carefully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.B Discussion:** In a paragraph, explain your decision about which features were dropped\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.C: Drop Problematic **samples** \n",
    "\n",
    "There could be several reasons why you might want to drop a sample:\n",
    "- It has  \"too many\" null values \n",
    "- It has a null value in the target\n",
    "- It contains outliers, especially in the target\n",
    "\n",
    "\n",
    "\n",
    "Your code in the next cell(s). Make a judgement call about which samples should be dropped and briefly describe your reasoning in the discussion.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **3.C Discussion:** In a short paragraph, explain your decision about which samples were dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.D: Impute for the remaining missing values\n",
    "\n",
    "Review the methods for imputation in **Appendix 2** and choose how you will impute the remainder of the missing values. Note:\n",
    "- Consider whether different methods are justified for different features.\n",
    "- In the next cells, apply your imputation methods to the dataset so that no null values remain after this step.\n",
    "- Answer the discussion question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.D Discussion:**  Describe in a paragraph your decisions about which methods you used to impute missing values in the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.E: Encode the Categorical Features (if any)\n",
    "\n",
    "You may not have any categorical features. If you do, encode them in the next step. No discussion is necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4:  Investigate Feature Relationships  [6 pts]\n",
    "\n",
    "In this part, we will investigate the feature relationships as a way of understanding the data.  In the next part, we'll investigate potential feature engineering opportunities.\n",
    "\n",
    "**Note:**  We won't be committing to any changes to the data until Milestone 2, as our choice of transformations will very much depend on the model we're building. But investigating these aspects of the data is an essential step in the first stages of our project. \n",
    "\n",
    "### Part 4.A:\n",
    "\n",
    "   - Compute and analyze pairwise correlations using a correlation matrix.\n",
    "   - Compute the F-statistic for all features for a better view of the relationships (displaying them in a bar chart would be useful as well). \n",
    "   - Identify features with strong correlations or notable relationships that may impact model performance.\n",
    "   - Investigate forward and backward feature selection\n",
    "        - Run these algorithms to investigate possible feature selection (don't commit to any selections yet)\n",
    "\n",
    "Your code below, in multiple cells with descriptive comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.A Discussion:**  Describe in a paragraph what you see in the feature relationships and correlations.\n",
    "\n",
    "Pay particular attention to especially interesting and/or strongly correlated feature relationships. \n",
    " How do the different methods for seeing relationships compare? Do they agree or disagree?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4.B:  2-Dimensional Visualizations for Interesting Patterns  \n",
    "   - Select three (3) pairs of features that exhibit meaningful relationships based on your previous analysis. \n",
    "   - Create 2D scatter plots or density plots to explore interactions between these features.  \n",
    "   - Provide brief interpretations of any observed patterns or trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.B Discussion:** Provide brief interpretations of any observed patterns or trends.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5:  Feature Engineering: Investigate various transformations to better expose the underlying data patterns to machine learning algorithms. [6 pts]\n",
    "\n",
    "**Important Notes:**  \n",
    "- This last part is a bit open ended, since there is a huge variety of feature engineering techniques, most of which won't be useful for your particular dataset. \n",
    "- Understand that you can't evaluate the final usefulness of these transformations\n",
    "until you choose a model, and  models may respond differently to various transformations or obviate some transformations (e.g., ensemble methods already do feature selection). \n",
    "- Therefore, write your transformations as functions or otherwise be prepared\n",
    "to choose later on which transformations may be necessary. \n",
    "\n",
    "**Investigate feature engineering, where appropriate:**\n",
    "\n",
    "- Feature scaling: standardize or normalize features as necessary\n",
    "- Decompose features (e.g., categorical into One-Hot feature sequence, date/time into two features data and time, etc.).\n",
    "- Add promising transformations of features\n",
    "    - Exponential $\\exp(x_i)$ or logarithmic $\\log(x_j)$\n",
    "    - Polynomial features  ( $x_i^2$, $x_i - x_j$), products ($x_i*x_j$), or ratios ($x_i/x_j$)\n",
    "\n",
    "**ToDo:**\n",
    "- Pick at least three transformations to try.\n",
    "- Try each one and evaluate its effect using correlations or F-scores or a feature selection algorithm.\n",
    "- Answer the discussion question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5 Discussion:** Describe in a paragraph why you chose these transformations and what you observed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Appendix 1: Features of the Zillow Dataset**  \n",
    "\n",
    "0. **parcelid**: Unique identifier for the property parcel.  \n",
    "1. **airconditioningtypeid**: Identifier for the type of air conditioning installed.  \n",
    "2. **architecturalstyletypeid**: Identifier for the architectural style of the property.  \n",
    "3. **basementsqft**: Square footage of the basement.  \n",
    "4. **bathroomcnt**: Number of bathrooms.  \n",
    "5. **bedroomcnt**: Number of bedrooms.  \n",
    "6. **buildingclasstypeid**: Identifier for the building framing type (e.g., wood frame, steel frame).  \n",
    "7. **buildingqualitytypeid**: Numeric value indicating the quality of the building (higher values often indicate better quality).  \n",
    "8. **calculatedbathnbr**: Calculated number of bathrooms, including fractional bathrooms.  \n",
    "9. **decktypeid**: Identifier for the type of deck.  \n",
    "10. **finishedfloor1squarefeet**: Square footage of the finished area on the first floor.  \n",
    "11. **calculatedfinishedsquarefeet**: Total finished living area square footage.  \n",
    "12. **finishedsquarefeet12**: Finished living area square footage.  \n",
    "13. **finishedsquarefeet13**: Perimeter living area square footage.  \n",
    "14. **finishedsquarefeet15**: Total area.  \n",
    "15. **finishedsquarefeet50**: Square footage of the finished area on the upper floors.  \n",
    "16. **finishedsquarefeet6**: Base unfinished and finished area square footage.  \n",
    "17. **fips**: Federal Information Processing Standards code, uniquely identifying counties and county equivalents.  \n",
    "18. **fireplacecnt**: Number of fireplaces.  \n",
    "19. **fullbathcnt**: Number of full bathrooms.  \n",
    "20. **garagecarcnt**: Number of cars that can fit in the garage.  \n",
    "21. **garagetotalsqft**: Total square footage of the garage.  \n",
    "22. **hashottuborspa**: Indicates if the property has a hot tub or spa.  \n",
    "23. **heatingorsystemtypeid**: Identifier for the type of heating system.  \n",
    "24. **latitude**: Latitude coordinate of the property.  \n",
    "25. **longitude**: Longitude coordinate of the property.  \n",
    "26. **lotsizesquarefeet**: Lot size in square feet.  \n",
    "27. **poolcnt**: Number of pools on the property.  \n",
    "28. **poolsizesum**: Total square footage of all pools.  \n",
    "29. **pooltypeid10**: Identifier for spa or hot tub.  \n",
    "30. **pooltypeid2**: Identifier for pool with spa or hot tub.  \n",
    "31. **pooltypeid7**: Identifier for pool without hot tub or spa.  \n",
    "32. **propertycountylandusecode**: County land use code for the property.  \n",
    "33. **propertylandusetypeid**: Identifier for the property land use type.  \n",
    "34. **propertyzoningdesc**: Description of the property's zoning.  \n",
    "35. **rawcensustractandblock**: Unprocessed census tract and block identifier.  \n",
    "36. **regionidcity**: Identifier for the city.  \n",
    "37. **regionidcounty**: Identifier for the county.  \n",
    "38. **regionidneighborhood**: Identifier for the neighborhood.  \n",
    "39. **regionidzip**: Identifier for the ZIP code.  \n",
    "40. **roomcnt**: Total number of rooms.  \n",
    "41. **storytypeid**: Identifier for the type of stories in the building (e.g., basement, attic).  \n",
    "42. **threequarterbathnbr**: Number of 3/4 bathrooms (typically includes a shower but no tub).  \n",
    "43. **typeconstructiontypeid**: Identifier for the type of construction (e.g., frame, masonry).  \n",
    "44. **unitcnt**: Number of units in the building (e.g., for multi-family properties).  \n",
    "45. **yardbuildingsqft17**: Square footage of the 17th yard building (e.g., shed).  \n",
    "46. **yardbuildingsqft26**: Square footage of the 26th yard building.  \n",
    "47. **yearbuilt**: Year the property was built.  \n",
    "48. **numberofstories**: Number of stories in the building.  \n",
    "49. **fireplaceflag**: Indicates if the property has a fireplace.  \n",
    "50. **assessmentyear**: Year the property was assessed.  \n",
    "51. **taxdelinquencyflag**: Indicates whether the property’s taxes are delinquent. Often “Y” if taxes are past due; otherwise null/empty.  \n",
    "52. **taxdelinquencyyear**: The year in which the property’s taxes became delinquent.  \n",
    "53. **censustractandblock**: A combined identifier for the property’s census tract and block group (part of the U.S. Census geographic hierarchy).  \n",
    "54. **taxvaluedollarcnt**: Total assessed value of the property (land plus structure) in dollars.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2: Summary of Basic Imputation Methods\n",
    "Imputation depends on the data type and context. Below are common techniques for handling missing values.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Simple Imputation (Basic Methods)**\n",
    "| Method | Best For | Code Example | Pros | Cons |\n",
    "|--------|---------|--------------|------|------|\n",
    "| **Drop Missing Values** | Few missing values (<5% of data) | `df.dropna()` | Quick and easy | Can remove valuable data |\n",
    "| **Mean Imputation** | Normally distributed numerical data | `df.fillna(df.mean())` | Preserves mean; simple | Distorts variance, weak for skewed data |\n",
    "| **Median Imputation** | Skewed numerical data | `df.fillna(df.median())` | Robust to outliers | May not capture patterns |\n",
    "| **Mode Imputation** | Categorical features | `df.fillna(df.mode().iloc[0])` | Keeps most common category | Can introduce bias |\n",
    "| **Constant Value (e.g., 0)** | Special cases (e.g., unknown numerical data) | `df.fillna(0)` | Simple and interpretable | Can mislead model |\n",
    "| **\"Unknown\" Category Imputation** (**New Addition**) | Categorical features with missing values | `df.fillna('Unknown')` | Keeps all rows, prevents data loss | May introduce artificial category |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Statistical & Advanced Imputation**\n",
    "| Method | Best For | Code Example | Pros | Cons |\n",
    "|--------|---------|--------------|------|------|\n",
    "| **Interpolation** | Time series, ordered data | `df.interpolate(method='linear')` | Preserves trends | May not work for non-continuous data |\n",
    "| **K-Nearest Neighbors (KNN)** | Small datasets, patterns in features | `KNNImputer(n_neighbors=5).fit_transform(df)` | Uses similar observations | Computationally expensive |\n",
    "| **Multivariate Imputation (MICE)** | Complex relationships between variables | `IterativeImputer().fit_transform(df)` | Captures relationships | Slower than mean/median |\n",
    "| **Regression Imputation** | When missing values depend on other variables | Train regression model to predict missing values | More accurate than mean/median | Risk of overfitting |\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use \"Unknown\" Category for Categorical Imputation**\n",
    "✅ **Good for:**\n",
    "- Categorical features where missing values may indicate meaningful differences.  \n",
    "- Customer data (e.g., missing survey responses → \"No Response\").  \n",
    "- Product categories where missing could be a separate group.  \n",
    "\n",
    "❌ **Avoid if:**\n",
    "- The missing category does **not** have a meaningful interpretation.\n",
    "- The model might learn spurious patterns from an artificial category.\n",
    "\n",
    "---\n",
    "\n",
    "### **Which Method to Choose?**\n",
    "| Scenario | Best Method |\n",
    "|----------|------------|\n",
    "| **Few missing values (<5%)** | Drop NaNs (`df.dropna()`) |\n",
    "| **Numerical & normal distribution** | Mean (`df.fillna(df.mean())`) |\n",
    "| **Numerical & skewed distribution** | Median (`df.fillna(df.median())`) |\n",
    "| **Categorical features** | Mode (`df.fillna(df.mode().iloc[0])`) |\n",
    "| **Categorical with possible meaning in missingness** | \"Unknown\" Category (`df.fillna('Unknown')`) |\n",
    "| **Small dataset with patterns** | KNN Imputer (`KNNImputer()`) |\n",
    "| **Complex relationships between features** | MICE / Iterative Imputer |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
